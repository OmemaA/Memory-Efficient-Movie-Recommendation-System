{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where we got the data\n",
    "We got the data from grouplens. http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-2k-v2.zip\n",
    "This was the same data that was used in the research paper. It contains many files in .dat extension.\n",
    "We chose to use movie_actors, movie_countries, movie_directors, movie_genres, movie_locations, tags, movies, and tags file for our learning model. We will use user_ratedmovies later for our recommendations.\n",
    "\n",
    "## How we converted data into dat files\n",
    "The procedure to convert these files from dat to csv was to use this [stackoverflow link](https://stackoverflow.com/questions/11483920/convert-dat-files-to-either-dta-shp-bdf-or-csv) to make the files into csv. Delimiter was kept as tab.\n",
    "Then the issue was of encoding. This [link](https://stackoverflow.com/questions/7256049/how-do-i-convert-an-ansi-encoded-file-to-utf-8-with-notepad) to change encoding to utf-8 with notepad by going to save as and changing encoding so pandas could read the data. There was an attempt to set encoding the file in utf-16-le [as stated here](https://stackoverflow.com/questions/43786852/python-pandas-load-csv-ansi-format-as-utf-8) but that attempt was unsuccessful hence encoding set to utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Omema Ahmed\\\\Desktop\\\\Ds2 Project\\\\cs201-spr20-proj--cs201-s20-domination-association-Data-processing'"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movie_actors = pd.read_csv(\"Data Refined\\\\movie_actors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_countries = pd.read_csv(\"Data Refined\\\\movie_countries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_directors = pd.read_csv(\"Data Refined\\\\movie_directors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres = pd.read_csv(\"Data Refined\\\\movie_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_locations = pd.read_csv(\"Data Refined\\\\movie_locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tags = pd.read_csv(\"Data Refined\\\\movie_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"Data Refined\\\\movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv(\"Data Refined\\\\tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discarding unnecessary columns\n",
    "final_table = movies[movies.columns[:6]]\n",
    "\n",
    "#removing imdb ID and picture URL, and spanishTitle column\n",
    "final_table= final_table.drop([\"imdbID\", \"spanishTitle\", \"imdbPictureURL\"], axis=1)\n",
    "\n",
    "#merging countries table with movies\n",
    "final_table = final_table.merge(movie_countries,left_on=\"id\", right_on=\"movieID\")\n",
    "\n",
    "#merging directors table with movies\n",
    "final_table = final_table.merge(movie_directors,left_on=\"id\", right_on=\"movieID\")\n",
    "\n",
    "#merging tags table with movies\n",
    "final_table = final_table.merge(tags, on =\"id\")\n",
    "\n",
    "#removing unnecessary columns\n",
    "final_table= final_table.drop([\"movieID_x\", \"movieID_y\", \"directorID\"], axis=1)\n",
    "\n",
    "#creating dictionaries to store genres, actors and locations against movieIDs\n",
    "genres_dict, actors_dict, loc_dict ={}, {}, {}\n",
    "\n",
    "for i in movie_genres.iterrows():\n",
    "    if i[1][0] not in genres_dict:\n",
    "        genres_dict[i[1][0]] = []\n",
    "    genres_dict[i[1][0]].append(i[1][1])\n",
    "\n",
    "for i in movie_actors.iterrows():\n",
    "    if i[1][0] not in actors_dict:\n",
    "        actors_dict[i[1][0]] = []\n",
    "    actors_dict[i[1][0]].append(i[1][2])\n",
    "\n",
    "for i in movie_locations.iterrows():\n",
    "    if i[1][0] not in loc_dict:\n",
    "        loc_dict[i[1][0]] = []\n",
    "    for x in range(1,4):\n",
    "        if i[1][x] not in loc_dict[i[1][0]] and isinstance(i[1][x],str):\n",
    "            loc_dict[i[1][0]].append(i[1][x])\n",
    "# print(loc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Toy story', 1995, 'USA', 'John Lasseter', 'earth', 'Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy', 'Annie Potts', 'Bill Farmer', 'Don Rickles', 'Erik von Detten', 'Greg Berg', 'Jack Angel', 'Jan Rabson', 'Jim Varney', 'Joan Cusack', 'Joe Ranft', 'John Morris', 'John Ratzenberger', 'Kendall Cunningham', 'Laurie Metcalf', 'Patrick Pinney', 'Penn Jillette', 'Philip Proctor', 'R. Lee Ermey', 'Sarah Freeman', 'Scott McAfee', 'Sherry Lynn', 'Tim Allen', 'Tom Hanks', 'Wallace Shawn']\n",
      "['Jumanji', 1995, 'USA', 'Joe Johnston', 'police', 'Adventure', 'Children', 'Fantasy', 'Peter Bryant', 'Adam Hann-Byrd', 'Bebe Neuwirth', 'Bonnie Hunt', 'Bradley Pierce', 'Darryl Henriques', 'David Alan Grier', 'David Hyde Pierce', 'Gillian Barber', 'James Handy', 'Jonathan Hyde', 'Kirsten Dunst', 'Laura Bell Bundy', 'Lloyd Berry', 'Malcolm Stewart', 'Patricia Clarkson', 'Robin Driscoll', 'Robin Williams', 'Canada', 'British Columbia', 'Delta', 'Maple Ridge', 'Vancouver', 'USA', 'Maine', 'Kennebunk', 'North Berwick', 'New Hampshire', 'Keene', 'Swanzey']\n",
      "['Grumpy Old Men', 1993, 'USA', 'Donald Petrie', 'boxing', 'Comedy', 'Romance', 'Ann-Margret', 'Buck Henry', 'Buffy Sedlachek', 'Burgess Meredith', 'Christopher McDonald', 'Daryl Hannah', 'Isabell Monk', 'Jack Lemmon', 'Joe Howard', 'John Carroll Lynch', 'Kevin Pollak', 'Ollie Osterberg', 'Ossie Davis', 'Sharon Howard-Field', 'Steve Cochran', 'Walter Matthau', 'USA', 'California', 'Burbank', 'Minnesota', 'Center City', 'Chanhassen', 'Faribault', 'Red Wing', 'Rockford', 'South St. Paul', 'St. Paul', 'Stillwater']\n",
      "['Waiting to Exhale', 1995, 'USA', 'Forest Whitaker', 'painter', 'Comedy', 'Drama', 'Romance', 'Leon', 'Angela Bassett', 'Brandon Hammond', 'Dennis Haysbert', 'Donald Faison', 'Ezra Swerdlow', 'Giancarlo Esposito', 'Graham Galloway', 'Gregory Hines', 'Jeffrey D. Sams', 'Lamont Johnson', 'Lela Rochon', 'Loretta Devine', 'Michael Beach', 'Mykelti Williamson', 'Starletta DuPois', 'Wendell Pierce', 'Wesley Snipes', 'Whitney Houston', 'Wren T. Brown', 'USA', 'Arizona', 'Chandler', 'Fountain Hills', 'Paradise Valley', 'Phoenix', 'Utah', 'Monument Valley']\n"
     ]
    }
   ],
   "source": [
    "#creating dictionary to store all movie details against movieIDs\n",
    "final_dict = {}\n",
    "for i in final_table.iterrows():\n",
    "    if i[1][0] not in final_dict:\n",
    "        final_dict[i[1][0]] = []\n",
    "    #adding title, year, country and director\n",
    "    for x in range(1,6):\n",
    "        final_dict[i[1][0]].append(i[1][x])\n",
    "    #adding genres\n",
    "    if i[1][0] in genres_dict and len(genres_dict[i[1][0]]) != 0:\n",
    "        for val in genres_dict[i[1][0]]:\n",
    "            final_dict[i[1][0]].append(val)\n",
    "    #adding actors\n",
    "    if i[1][0] in actors_dict and len(actors_dict[i[1][0]]) != 0:\n",
    "        for val in actors_dict[i[1][0]]:\n",
    "            final_dict[i[1][0]].append(val)\n",
    "    #adding locations\n",
    "    if i[1][0] in loc_dict and len(loc_dict[i[1][0]]) != 0:\n",
    "        for val in loc_dict[i[1][0]]:\n",
    "            final_dict[i[1][0]].append(val)\n",
    "# for i in range(1,5):\n",
    "#     print(final_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import bitarray\n",
    "import mmh3\n",
    "\n",
    "class bloomFilter():\n",
    "    def __init__(self, total):        \n",
    "        #calculates false positive probability\n",
    "        # self.fp = self.get_fp()\n",
    "        self.fp = 0.001\n",
    "\n",
    "        #calculates the size of bit array\n",
    "        self.bits = self.get_size(total, self.fp)\n",
    "        # print(self.bits)\n",
    "\n",
    "        #calculates optimum numb of hash function to use\n",
    "        self.totalhash = self.get_total_hash(self.bits, total)\n",
    "        # print(self.totalhash)\n",
    "\n",
    "        #creates a bit array of the given size\n",
    "        self.bitarray = bitarray.bitarray(self.bits)\n",
    "\n",
    "        #initializes all bits to 0\n",
    "        self.bitarray.setall(0)\n",
    "\n",
    "        #total items added\n",
    "        self.items = 0\n",
    "\n",
    "    def get_fp(self):\n",
    "        return (1- math.exp(-(self.totalhash * self.items) / self.bits)) ** self.totalhash\n",
    "\n",
    "    def add(self, element):\n",
    "        for i in self.element_index(element):\n",
    "            self.bitarray[i] = 1\n",
    "        self.items += 1 \n",
    "\n",
    "    def check(self, element):\n",
    "        for i in self.element_index(element):\n",
    "            if self.bitarray[i] == 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def get_size(self, total, fp):\n",
    "        m = -(total* math.log(fp))/(math.log(2)**2)\n",
    "        return round(m) \n",
    "\n",
    "    def get_total_hash(self, bits, total):\n",
    "        k = (bits/total) * math.log(2)\n",
    "        return round(k)        \n",
    "\n",
    "    def hash_index(self, hash):\n",
    "        return hash % self.bits\n",
    "    \n",
    "    def element_index(self, element):\n",
    "        return [self.hash_index(mmh3.hash(element, i))for i in range(self.totalhash)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Toy story': bitarray('10000000000000000000000000000000001000000100000000010000000000000000000001000000010000000010100001000010000010010000000000000001000000000000000110000010011000100000001000000000000010000010000000100101001000000001000000000000000010000101000010010100000000001000001100000000010000001010000000000000000000000001011000000010000000000000100000000000000000010001000000000000000000000000000000000000000010000000010000000000000000100000000001000000100000000000000000000100010100000100010010000000000000000000000000000010000000000000000010000000000000000000000100000000100000001000000000000010000010101000100000000000000100000001000000000000001000010010000010001000000000010000001000000000001000000000001000010000000001100100000000000010100010000000000000000000000001000010000000000000000000000010000000000000000100000000000001001000000000000001000110000000000000010000000000000000000000000100000100000100000000010000000000000000001100010000001010000000001000000000000000000000000000100000010010000100000001100001000100000000000000000000000000000000000000000000100010000000010000000110010000000000000000010000100000000000000000001000000011000000000010000100010000000000000000100010000000000000000000000000000000000000001100000000001000001000000000000001000001000000000000000100000000000010000000000000000000100000100100000010000000000000000000000000000010100000000001000000000101000000010000000000010000000000000000000000000000000000000000000000100000000000000000001000000000000000001000000011010000000000000001000000000000000000000000001000011000010000001000000000000000000000011000000000000000000000100000010110001100110010000000001001000000010000000000000000000000000000000100010000000000000000000000000000000000100000000000001000000000100000000001000000000000000000000000000000000000000000000000000000000000000000000000001000000000000101000000000000000000000000000000000000000000000000000001000000000100000000000000000000000000000010000000000000000001000000000000000000100000001000000100000100010000000000000000000100100000000010000010000000000001000000001100100100000000000000000000000010001000000010001100000000000000000000000100000000000000000011110000010000000000000000000000011000000000000000000101000000000000000000001000010100000000000001000000000000000000000000000000000000000001100000010000001000000000000000000000001000000010000000000001000000000010000000000000000000100000110001100001000000000000001001000000010010000000100000100000000000010000000000000100000100010001000000000100001000000000000100000000000000000000000000000000000000001000010000000000010000000000000000000000010000000000000000001000000010000000000000010000000100010001101010000000100000000001001000000000000100000000000000000000000000000000000000001000000000000000000000000000000000000000000001000000000000100000000000000000000000000000000000000100010000000100000001000000100000000010000000000110001001000000000000000101000001001000000000000000010000000000000000010000000000000000000000000000000010000010000000000000000010100000000000001000000000000000000000000100010000000100000000100000100000000000000000010000000010010000000000000010000000000000000000000100000000000000010000000001010000000000000000000000000000000001000000000000000100001000000010000010000010000000000000000000000001000000000000000000000000000000000001000000101010000010000000000000000000000000000000000000000000000000000000001000000001000000000000000000100000000')}\n"
     ]
    }
   ],
   "source": [
    "bloom_filters = {}\n",
    "for i in final_dict:\n",
    "    if final_dict[i][0] not in bloom_filters:\n",
    "        obj = bloomFilter(237)\n",
    "        for x in final_dict[i]:\n",
    "            obj.add(str(x))\n",
    "        bloom_filters[final_dict[i][0]] = obj.bitarray\n",
    "        break\n",
    "print(bloom_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
